# üìò Guide Complet ‚Äî Syst√®me de D√©tection d'Objets pour la Conduite Autonome

> **Projet PFE** | F√©vrier 2026  
> Ce guide vous accompagne jour par jour, de la pr√©paration des donn√©es jusqu'√† l'entra√Ænement YOLO.

---

## üìÖ Calendrier R√©sum√©

| Jour | √âtape | Objectif |
|------|-------|----------|
| 1 | Structure du projet | ‚úÖ **Fait** ‚Äî R√©pertoires et scripts cr√©√©s |
| 1‚Äì2 | T√©l√©charger COCO 2017 | Obtenir images + labels via script automatique |
| 3 | Filtrer les classes | Garder uniquement les 18 classes cibles |
| 4 | Nettoyer le dataset | Supprimer les fichiers invalides |
| 5 | √âquilibrer le dataset | Corriger les classes sous-repr√©sent√©es |
| 6 | Diviser le dataset | Train 70% / Val 20% / Test 10% |
| 6 | Configurer dataset.yaml | ‚úÖ **Fait** ‚Äî Pr√™t pour l'entra√Ænement YOLO |
| 7+ | Compl√©ter les classes manquantes | Ajouter GTSRB, donn√©es custom, etc. |

---

## üß© √âTAPE 1 ‚Äî Structure du Projet ‚úÖ FAIT

```
autonomous_vision/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/              ‚Üê Donn√©es t√©l√©charg√©es brutes
‚îÇ   ‚îú‚îÄ‚îÄ processed/        ‚Üê Apr√®s filtrage et nettoyage
‚îÇ   ‚îú‚îÄ‚îÄ train/            ‚Üê 70% pour l'entra√Ænement
‚îÇ   ‚îú‚îÄ‚îÄ val/              ‚Üê 20% pour la validation
‚îÇ   ‚îî‚îÄ‚îÄ test/             ‚Üê 10% pour les tests
‚îú‚îÄ‚îÄ scripts/              ‚Üê Scripts de traitement
‚îú‚îÄ‚îÄ dataset.yaml          ‚Üê Config YOLO
‚îî‚îÄ‚îÄ README.md
```

---

## üß© √âTAPE 2 ‚Äî T√©l√©charger le Dataset COCO 2017 (Jour 1‚Äì2)

### Pourquoi COCO ?
- **330 000 images** dont beaucoup de sc√®nes de conduite
- 8 des 18 classes cibles disponibles directement
- **T√©l√©chargement automatique** via script (pas d'inscription manuelle)
- Labels de d√©tection de haute qualit√©

### Pr√©requis ‚Äî Installer les d√©pendances

```bash
pip install fiftyone ultralytics Pillow
```

> [!NOTE]
> FiftyOne t√©l√©charge COCO depuis les serveurs officiels. La premi√®re ex√©cution peut prendre du temps (~20 Go).

### Commande √† ex√©cuter

```bash
cd autonomous_vision

# üß™ Test rapide d'abord (500 images ‚Äî v√©rifier que tout fonctionne)
python scripts/download_coco.py --max-samples 500

# üöÄ T√©l√©chargement complet (toutes les images pertinentes)
python scripts/download_coco.py
```

### Options disponibles

| Option | Description |
|--------|-------------|
| `--max-samples 500` | Limiter le nombre d'images (pour tester) |
| `--split train` | T√©l√©charger uniquement le split train |
| `--split validation` | T√©l√©charger uniquement le split validation |
| `--split both` | T√©l√©charger les deux (par d√©faut) |

### Ce que fait le script

1. üì• T√©l√©charge COCO 2017 via FiftyOne
2. üîç Filtre uniquement les 8 classes pertinentes pour la conduite
3. üì¶ Exporte en format YOLO (`.txt`)
4. üîÑ Remappe les class IDs vers notre num√©rotation (0‚Äì17)
5. üìÅ Organise tout dans `data/raw/images/` et `data/raw/labels/`

### R√©sultat attendu
```
üì• Downloading COCO 2017 ‚Äî train split
‚úÖ Downloaded 82783 samples
   After filtering: ~45000 samples with target classes
üì¶ Exporting to YOLO format ‚Üí data/coco_export
üîÑ Remapped 45000 label files to target class IDs
üìÅ Organized into data/raw:
   Images: 45000
   Labels: 45000
üéâ COCO Download Complete!
```

### Classes couvertes par COCO

| ‚úÖ Couvertes (8/18) | ‚ùå √Ä compl√©ter plus tard (10/18) |
|--------------------|----------------------------------|
| car, truck, bus | cyclist |
| motorcycle, bicycle | traffic_light_green, traffic_light_yellow |
| pedestrian | speed_limit_sign, yield_sign, no_entry_sign |
| traffic_light (‚Üí red), stop_sign | road_barrier, cone, pothole, crosswalk |

> [!TIP]
> **Alternative : BDD100K** ‚Äî Si vous pr√©f√©rez des images sp√©cifiquement de conduite,
> vous pouvez t√©l√©charger BDD100K manuellement depuis [bdd-data.berkeley.edu](https://bdd-data.berkeley.edu/).
> Dans ce cas, changez `CLASS_MAPPING = BDD100K_MAPPING` dans `filter_classes.py`.

### Format YOLO (g√©n√©r√© automatiquement)

Chaque fichier `.txt` dans `data/raw/labels/` contient :
```
# <class_id> <x_center> <y_center> <width> <height>
# Toutes les valeurs sont normalis√©es entre 0 et 1
0 0.4532 0.6210 0.1200 0.2500
5 0.7800 0.5500 0.0400 0.1800
```

---

## üß© √âTAPE 3 ‚Äî Filtrer les Classes (Jour 3)

### Objectif
Garder uniquement les **18 classes cibles** et supprimer tout le reste.

### Les 18 classes du projet

| ID | Classe | Cat√©gorie | Source |
|----|--------|-----------|--------|
| 0 | `car` | V√©hicule | COCO ‚úÖ |
| 1 | `truck` | V√©hicule | COCO ‚úÖ |
| 2 | `bus` | V√©hicule | COCO ‚úÖ |
| 3 | `motorcycle` | V√©hicule | COCO ‚úÖ |
| 4 | `bicycle` | V√©hicule | COCO ‚úÖ |
| 5 | `pedestrian` | Usager Vuln√©rable | COCO ‚úÖ |
| 6 | `cyclist` | Usager Vuln√©rable | ‚è≥ BDD100K / Custom |
| 7 | `traffic_light_red` | Signalisation | COCO ‚ö†Ô∏è (√† raffiner par couleur) |
| 8 | `traffic_light_green` | Signalisation | ‚è≥ √Ä raffiner depuis COCO |
| 9 | `traffic_light_yellow` | Signalisation | ‚è≥ √Ä raffiner depuis COCO |
| 10 | `stop_sign` | Signalisation | COCO ‚úÖ |
| 11 | `speed_limit_sign` | Signalisation | ‚è≥ GTSRB / Mapillary |
| 12 | `yield_sign` | Signalisation | ‚è≥ GTSRB / Mapillary |
| 13 | `no_entry_sign` | Signalisation | ‚è≥ GTSRB / Mapillary |
| 14 | `road_barrier` | Obstacle | ‚è≥ Custom / CARLA |
| 15 | `cone` | Obstacle | ‚è≥ Custom / CARLA |
| 16 | `pothole` | Obstacle | ‚è≥ Custom / Kaggle |
| 17 | `crosswalk` | Route | ‚è≥ Custom |

### Commande √† ex√©cuter

```bash
cd autonomous_vision
python scripts/filter_classes.py --raw-dir data/raw --out-dir data/processed
```

### R√©sultat attendu
```
üìÇ Found 70000 label files in data/raw/labels
‚úÖ Filtering complete!
   Kept:    58000 images
   Dropped: 12000 images (no valid objects)
üìä Class distribution:
   car                 : 120000
   pedestrian          :  45000
   truck               :  12000
   ...
```

---

## üß© √âTAPE 4 ‚Äî Nettoyer le Dataset (Jour 4)

### Objectif
Supprimer les fichiers probl√©matiques :
- ‚ùå Labels vides (0 octets)
- ‚ùå Labels sans image correspondante
- ‚ùå Images sans label correspondant
- ‚ùå Images corrompues / illisibles
- ‚ùå Labels avec format invalide

### Commande √† ex√©cuter

```bash
# D'abord, pr√©visualiser ce qui sera supprim√© (sans rien supprimer)
python scripts/clean_dataset.py --data-dir data/processed --dry-run

# Si tout semble correct, nettoyer pour de vrai
python scripts/clean_dataset.py --data-dir data/processed
```

### Pr√©requis
```bash
pip install Pillow    # Pour v√©rifier les images corrompues
```

---

## üß© √âTAPE 5 ‚Äî √âquilibrer le Dataset (Jour 5)

### Le probl√®me
```
car          : 120000  ‚Üê Beaucoup trop
stop_sign    :    500  ‚Üê Pas assez !
cone         :     50  ‚Üê Le mod√®le va ignorer cette classe
```

Si le dataset est d√©s√©quilibr√©, **le mod√®le ignore les classes rares**.

### Commande √† ex√©cuter

```bash
# √âtape 1 : Analyser la distribution (ne modifie rien)
python scripts/balance_dataset.py --data-dir data/processed --analyze-only

# √âtape 2 : √âquilibrer (augmenter les classes rares √† minimum 1000 objets)
python scripts/balance_dataset.py --data-dir data/processed --min-objects 1000
```

### Ce que fait le script
1. Compte les objets par classe
2. Pour chaque classe sous le seuil :
   - Duplique des images contenant cette classe
   - Applique des augmentations simples (luminosit√©, contraste, flou, flip)
   - Ajuste les labels en cons√©quence

---

## üß© √âTAPE 6 ‚Äî Diviser le Dataset (Jour 6)

### Commande √† ex√©cuter

```bash
python scripts/split_dataset.py --src-dir data/processed --out-dir data --copy
```

### R√©sultat

| Split | Pourcentage | R√©pertoire |
|-------|-------------|------------|
| Train | 70% | `data/train/images/` + `data/train/labels/` |
| Val | 20% | `data/val/images/` + `data/val/labels/` |
| Test | 10% | `data/test/images/` + `data/test/labels/` |

> [!IMPORTANT]
> Utilisez `--copy` pour garder les donn√©es originales dans `data/processed/` en backup.
> Sans `--copy`, les fichiers sont **d√©plac√©s** (pas de backup).

---

## üß© √âTAPE 7 ‚Äî V√©rifier dataset.yaml (Jour 6)

Le fichier `dataset.yaml` est d√©j√† configur√© avec les 18 classes :

```yaml
path: data
train: train/images
val: val/images
test: test/images

nc: 18
names:
  0: car
  1: truck
  2: bus
  # ... (18 classes au total)
  17: crosswalk
```

> Ce fichier sera utilis√© directement par Ultralytics YOLO pour l'entra√Ænement.

---

## üß© √âTAPE 8 ‚Äî Compl√©ter les Classes Manquantes (Jour 7+)

COCO couvre 8 des 18 classes. Voici comment compl√©ter les 10 restantes :

### Sources recommand√©es

| Classes manquantes | Dataset | Lien |
|-------------------|---------|------|
| `cyclist` | **BDD100K** (rider class) | [bdd-data.berkeley.edu](https://bdd-data.berkeley.edu/) |
| `traffic_light_green/yellow` | Raffiner depuis les d√©tections COCO | Script custom √† cr√©er |
| `speed_limit_sign`, `yield_sign`, `no_entry_sign` | **GTSRB** | [benchmark.ini.rub.de](https://benchmark.ini.rub.de/) |
| `road_barrier`, `cone` | **CARLA Simulator** ou collection personnelle | [carla.org](https://carla.org/) |
| `pothole` | **Kaggle Pothole Dataset** | Chercher "pothole detection" sur Kaggle |
| `crosswalk` | **Collection personnelle** | Dashcam footage |

### Processus pour chaque source suppl√©mentaire

1. T√©l√©charger le dataset
2. Convertir les labels en format YOLO
3. Remapper les class IDs vers notre num√©rotation (0‚Äì17)
4. Copier dans `data/processed/images/` et `data/processed/labels/`
5. Re-ex√©cuter `clean_dataset.py` et `balance_dataset.py`
6. Re-ex√©cuter `split_dataset.py`

---

## üß© √âTAPE 9 ‚Äî Entra√Æner avec YOLO (Phase 3 du projet)

### Sur Kaggle Notebook (GPU gratuit)

```python
from ultralytics import YOLO

# Charger le mod√®le pr√©-entra√Æn√©
model = YOLO("yolov8s.pt")

# Lancer l'entra√Ænement
results = model.train(
    data="dataset.yaml",
    epochs=100,
    imgsz=640,
    batch=16,
    device=0,
)
```

> Voir le rapport complet (`AI_Object_Detection_System_Report.md`) pour les param√®tres d√©taill√©s et la configuration Kaggle.

---

## üìã Checklist R√©sum√©e

- [x] Cr√©er la structure du projet
- [x] Cr√©er les scripts de traitement
- [x] Cr√©er le script de t√©l√©chargement COCO
- [x] Configurer `dataset.yaml` (18 classes)
- [ ] Installer les d√©pendances (`pip install fiftyone ultralytics Pillow`)
- [ ] Tester le t√©l√©chargement (`download_coco.py --max-samples 500`)
- [ ] Lancer le t√©l√©chargement complet (`download_coco.py`)
- [ ] Ex√©cuter `filter_classes.py`
- [ ] Ex√©cuter `clean_dataset.py`
- [ ] Ex√©cuter `balance_dataset.py`
- [ ] Ex√©cuter `split_dataset.py`
- [ ] T√©l√©charger les datasets compl√©mentaires (GTSRB, etc.)
- [ ] Lancer l'entra√Ænement YOLO sur Kaggle

---

## ‚ùì Besoin d'Aide ?

| Si vous √™tes bloqu√© sur... | Demandez-moi... |
|---------------------------|-----------------|
| Erreur avec FiftyOne | Copiez-collez l'erreur |
| Ajouter les donn√©es BDD100K | "Change le mapping pour BDD100K" |
| Convertir GTSRB | "Cr√©e un script pour convertir GTSRB en YOLO" |
| Entra√Ænement Kaggle | "Cr√©e le notebook Kaggle d'entra√Ænement" |
| Erreurs dans les scripts | Copiez-collez l'erreur |
| Module de distance | "Cr√©e le module d'estimation de distance" |

---

*Guide cr√©√© pour le Projet PFE ‚Äî D√©tection d'Objets par IA pour la Conduite Autonome*
